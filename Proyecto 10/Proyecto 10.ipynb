{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hola **Fernando**!\n",
    "\n",
    "Soy **Patricio Requena** üëã. Es un placer ser el revisor de tu proyecto el d√≠a de hoy!\n",
    "\n",
    "Revisar√© tu proyecto detenidamente con el objetivo de ayudarte a mejorar y perfeccionar tus habilidades. Durante mi revisi√≥n, identificar√© √°reas donde puedas hacer mejoras en tu c√≥digo, se√±alando espec√≠ficamente qu√© y c√≥mo podr√≠as ajustar para optimizar el rendimiento y la claridad de tu proyecto. Adem√°s, es importante para m√≠ destacar los aspectos que has manejado excepcionalmente bien. Reconocer tus fortalezas te ayudar√° a entender qu√© t√©cnicas y m√©todos est√°n funcionando a tu favor y c√≥mo puedes aplicarlos en futuras tareas. \n",
    "\n",
    "_**Recuerda que al final de este notebook encontrar√°s un comentario general de mi parte**_, empecemos!\n",
    "\n",
    "Encontrar√°s mis comentarios dentro de cajas verdes, amarillas o rojas, ‚ö†Ô∏è **por favor, no muevas, modifiques o borres mis comentarios** ‚ö†Ô∏è:\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "Si todo est√° perfecto.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "Si tu c√≥digo est√° bien pero se puede mejorar o hay alg√∫n detalle que le hace falta.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "Si de pronto hace falta algo o existe alg√∫n problema con tu c√≥digo o conclusiones.\n",
    "</div>\n",
    "\n",
    "Puedes responderme de esta forma:\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Respuesta del estudiante</b> <a class=‚ÄútocSkip‚Äù></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1 - Importamos las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "RND = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2 - Cargamos datos y revisamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/Churn.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3 - Reemplazar infinitos, revisar nulos y balance de la clase objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RowNumber            0\n",
      "CustomerId           0\n",
      "Surname              0\n",
      "CreditScore          0\n",
      "Geography            0\n",
      "Gender               0\n",
      "Age                  0\n",
      "Tenure             909\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Exited               0\n",
      "dtype: int64\n",
      "0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n",
      "0    0.796\n",
      "1    0.204\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Reemplazar infinitos por NaN (evita errores)\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Revisar nulos por columna\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Ver distribuci√≥n de la variable objetivo\n",
    "print(df['Exited'].value_counts())\n",
    "print(df['Exited'].value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Detectamos si hay nulos y confirmamos desbalance (habitual en este dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "\n",
    "Correcto! Siempre en proyectos de clasificaci√≥n utilizando Machine Learning hay que revisar el balance de las clases ya que de esto depender√° las t√©cnicas a aplicar o los modelos a utilizar para conseguir un buen desempe√±o en las predicciones\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4 ‚Äî Quitar columnas irrelevantes y codificar categor√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar columnas irrelevantes\n",
    "df = df.drop(columns=['RowNumber', 'CustomerId', 'Surname'])\n",
    "\n",
    "# convertir categ√≥ricas a dummies (Geography, Gender)\n",
    "df = pd.get_dummies(df, columns=['Geography', 'Gender'], drop_first=True)\n",
    "\n",
    "# separar X e y\n",
    "X = df.drop(columns=['Exited'])\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "X y y listos para partir en conjuntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5 - Dividir estratificado: train / val / test (60/20/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±os train/val/test: 6000 2000 2000\n",
      "Proporci√≥n en train: 0    0.796\n",
      "1    0.204\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=RND)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=RND)\n",
    "\n",
    "print(\"Tama√±os train/val/test:\", X_train.shape[0], X_val.shape[0], X_test.shape[0])\n",
    "print(\"Proporci√≥n en train:\", y_train.value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Tenemos conjuntos independientes; test no se toca hasta el final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6 - Imputar NaN usando la media del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN en train/val/test: 0 0 0\n"
     ]
    }
   ],
   "source": [
    "# SimpleImputer: aprender media en X_train y aplicar a val/test\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# fit en X_train, transform en train/val/test\n",
    "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X.columns, index=X_train.index)\n",
    "X_val   = pd.DataFrame(imputer.transform(X_val),   columns=X.columns, index=X_val.index)\n",
    "X_test  = pd.DataFrame(imputer.transform(X_test),  columns=X.columns, index=X_test.index)\n",
    "\n",
    "# Confirmar que ya no hay NaN\n",
    "print(\"NaN en train/val/test:\", X_train.isna().sum().sum(), X_val.isna().sum().sum(), X_test.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Ahora los datos no producir√°n el error de NaN al entrenar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 7 - Baseline simple (sin correcci√≥n del desbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF baseline - F1 (val): 0.561622464898596 AUC (val): 0.853280861755438\n",
      "LR baseline - F1 (val): 0.3189964157706094 AUC (val): 0.7561907053432477\n"
     ]
    }
   ],
   "source": [
    "# Baseline RandomForest (sin cambios)\n",
    "rf = RandomForestClassifier(random_state=RND)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Baseline LogisticRegression con escalado en pipeline\n",
    "pipe_lr = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(max_iter=2000, random_state=RND))])\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar en validation\n",
    "y_val_pred_rf = rf.predict(X_val)\n",
    "y_val_proba_rf = rf.predict_proba(X_val)[:,1]\n",
    "\n",
    "y_val_pred_lr = pipe_lr.predict(X_val)\n",
    "y_val_proba_lr = pipe_lr.predict_proba(X_val)[:,1]\n",
    "\n",
    "print(\"RF baseline - F1 (val):\", f1_score(y_val, y_val_pred_rf), \"AUC (val):\", roc_auc_score(y_val, y_val_proba_rf))\n",
    "print(\"LR baseline - F1 (val):\", f1_score(y_val, y_val_pred_lr), \"AUC (val):\", roc_auc_score(y_val, y_val_proba_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "\n",
    "Correccto, se puede ver que el desbalance afecta el desempe√±o de los modelos\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Anota F1 y AUC-ROC como baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 8 - M√©todo 1: class_weight='balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF class_weight - F1 (val): 0.5632 AUC: 0.856003923800534\n",
      "LR class_weight - F1 (val): 0.48 AUC: 0.7606898115372692\n"
     ]
    }
   ],
   "source": [
    "# RandomForest con class_weight\n",
    "rf_cw = RandomForestClassifier(class_weight='balanced', random_state=RND)\n",
    "rf_cw.fit(X_train, y_train)\n",
    "\n",
    "# LogisticRegression con class_weight en pipeline\n",
    "pipe_lr_cw = Pipeline([('scaler', StandardScaler()),\n",
    "                       ('lr', LogisticRegression(class_weight='balanced', max_iter=2000, random_state=RND))])\n",
    "pipe_lr_cw.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar en validation\n",
    "y_val_pred_rf_cw = rf_cw.predict(X_val)\n",
    "y_val_proba_rf_cw = rf_cw.predict_proba(X_val)[:,1]\n",
    "\n",
    "y_val_pred_lr_cw = pipe_lr_cw.predict(X_val)\n",
    "y_val_proba_lr_cw = pipe_lr_cw.predict_proba(X_val)[:,1]\n",
    "\n",
    "print(\"RF class_weight - F1 (val):\", f1_score(y_val, y_val_pred_rf_cw), \"AUC:\", roc_auc_score(y_val, y_val_proba_rf_cw))\n",
    "print(\"LR class_weight - F1 (val):\", f1_score(y_val, y_val_pred_lr_cw), \"AUC:\", roc_auc_score(y_val, y_val_proba_lr_cw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Compara estos F1 con el baseline para ver si mejora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 9 - M√©todo 2A: Undersampling (reducir clase mayoritaria) con resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF undersample - F1 (val): 0.586894586894587 AUC: 0.8514330971958091\n"
     ]
    }
   ],
   "source": [
    "# Preparar DataFrame de entrenamiento\n",
    "y_train.name = 'Exited'\n",
    "train_df = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# separar clases\n",
    "no_churn = train_df[train_df['Exited'] == 0]\n",
    "churn    = train_df[train_df['Exited'] == 1]\n",
    "\n",
    "# undersample: reducir no_churn al tama√±o de churn\n",
    "no_churn_down = resample(no_churn,\n",
    "                         replace=False,\n",
    "                         n_samples=len(churn),\n",
    "                         random_state=RND)\n",
    "\n",
    "train_under = pd.concat([no_churn_down, churn]).sample(frac=1, random_state=RND)  # barajar\n",
    "X_train_under = train_under.drop(columns=['Exited'])\n",
    "y_train_under = train_under['Exited']\n",
    "\n",
    "# entrenar un RF sobre los datos undersampleados\n",
    "rf_under = RandomForestClassifier(random_state=RND)\n",
    "rf_under.fit(X_train_under, y_train_under)\n",
    "\n",
    "# evaluar\n",
    "y_val_pred_under = rf_under.predict(X_val)\n",
    "y_val_proba_under = rf_under.predict_proba(X_val)[:,1]\n",
    "print(\"RF undersample - F1 (val):\", f1_score(y_val, y_val_pred_under), \"AUC:\", roc_auc_score(y_val, y_val_proba_under))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Puede subir recall, pero a veces reduce la informaci√≥n (porque borramos datos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "\n",
    "Perfecto, t√©cnicas c√≥mo sobre-muestreo o sub-muestreo o la modificaci√≥n de par√°metros en algunos modelos para especificar el desbalance ayuda a los modelos a poder generalizar mejor cada caso y obtener un buen desempe√±o\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 10 - M√©todo 2B: Oversampling simple (repetir casos minoritarios) con resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF oversample - F1 (val): 0.6179775280898876 AUC: 0.8551548466802704\n"
     ]
    }
   ],
   "source": [
    "# oversample: repetir churn hasta igualar no_churn\n",
    "churn_up = resample(churn,\n",
    "                    replace=True,\n",
    "                    n_samples=len(no_churn),\n",
    "                    random_state=RND)\n",
    "\n",
    "train_over = pd.concat([no_churn, churn_up]).sample(frac=1, random_state=RND)\n",
    "X_train_over = train_over.drop(columns=['Exited'])\n",
    "y_train_over = train_over['Exited']\n",
    "\n",
    "# entrenar RF sobre oversampled\n",
    "rf_over = RandomForestClassifier(random_state=RND)\n",
    "rf_over.fit(X_train_over, y_train_over)\n",
    "\n",
    "# evaluar\n",
    "y_val_pred_over = rf_over.predict(X_val)\n",
    "y_val_proba_over = rf_over.predict_proba(X_val)[:,1]\n",
    "print(\"RF oversample - F1 (val):\", f1_score(y_val, y_val_pred_over), \"AUC:\", roc_auc_score(y_val, y_val_proba_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Sencillo y f√°cil de explicar; puede ayudar si la clase minoritaria es peque√±a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 11 - Comparar resultados (val) y elegir el mejor seg√∫n F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RF F1: 0.561622464898596\n",
      "RF class_weight F1: 0.5632\n",
      "RF undersample F1: 0.586894586894587\n",
      "RF oversample F1: 0.6179775280898876\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline RF F1:\", f1_score(y_val, y_val_pred_rf))\n",
    "print(\"RF class_weight F1:\", f1_score(y_val, y_val_pred_rf_cw))\n",
    "print(\"RF undersample F1:\", f1_score(y_val, y_val_pred_under))\n",
    "print(\"RF oversample F1:\", f1_score(y_val, y_val_pred_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Elige best_model (por ejemplo rf_over o rf_cw) que tenga mayor F1 en validaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 12 - Afinar umbral (threshold) del mejor modelo para maximizar F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor umbral en val: 0.46 F1: 0.6230366492146596\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que 'best_model' es rf_over; ajusta si elegiste otro\n",
    "best_model = rf_over   # cambia si tu mejor fue otro\n",
    "probs_val = best_model.predict_proba(X_val)[:,1]\n",
    "\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "for t in np.linspace(0.01, 0.99, 99):\n",
    "    preds = (probs_val >= t).astype(int)\n",
    "    f = f1_score(y_val, preds)\n",
    "    if f > best_f1:\n",
    "        best_f1 = f\n",
    "        best_thresh = t\n",
    "\n",
    "print(\"Mejor umbral en val:\", best_thresh, \"F1:\", best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Usaremos best_thresh para evaluar en test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 13 - Evaluaci√≥n final en TEST (usar umbral optimizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 (test): 0.6047120418848168\n",
      "AUC-ROC (test): 0.8459160238821256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8929    0.9209    0.9067      1593\n",
      "           1     0.6471    0.5676    0.6047       407\n",
      "\n",
      "    accuracy                         0.8490      2000\n",
      "   macro avg     0.7700    0.7442    0.7557      2000\n",
      "weighted avg     0.8429    0.8490    0.8452      2000\n",
      "\n",
      "Matriz de confusi√≥n:\n",
      " [[1467  126]\n",
      " [ 176  231]]\n"
     ]
    }
   ],
   "source": [
    "probs_test = best_model.predict_proba(X_test)[:,1]\n",
    "y_test_pred = (probs_test >= best_thresh).astype(int)\n",
    "\n",
    "print(\"F1 (test):\", f1_score(y_test, y_test_pred))\n",
    "print(\"AUC-ROC (test):\", roc_auc_score(y_test, probs_test))\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "print(\"Matriz de confusi√≥n:\\n\", confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Estas son tus m√©tricas finales que presentar√°s (F1 y AUC-ROC). Si F1 ‚â• 0.59, cumpliste la condici√≥n del proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 14 - Conclusiones generales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Preprocesado:** elimin√© identificadores, apliqu√© get_dummies, reemplac√© inf por NaN y los imput√© con la media calculada sobre el conjunto de entrenamiento.\n",
    "\n",
    "- **Investigaci√≥n del desbalance:** Exited est√° desbalanceado (mostrar value_counts()), por lo que prob√© varios m√©todos.\n",
    "\n",
    "- **Baselines:** entren√© RandomForest y LogisticRegression sin correcci√≥n; obtuve F1 y AUC-ROC iniciales.\n",
    "\n",
    "- **Correcci√≥n de desbalance (m√≠nimo 2):**\n",
    "1. **class_weight='balanced'** (sin alterar datos).\n",
    "\n",
    "2. **resample de sklearn:** undersampling (reducir clase mayoritaria) y oversampling simple (duplicar clase minoritaria).\n",
    "\n",
    "- **Selecci√≥n y ajuste:** eleg√≠ el modelo con mayor F1 en validaci√≥n y optimic√© el umbral de probabilidad para maximizar F1.\n",
    "\n",
    "- **Resultados finales:** presentar F1 (test) y AUC-ROC (test) y la matriz de confusi√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "\n",
    "Te felicito por el trabajo realizado Fernando, se nota que conoces las m√©tricas de evaluaci√≥n y planteas conclusiones muy acertadas en cuanto a los resultados. Es importante siempre en un problema de ML identificar el balance entre las clases de tu variable objetivo para poder escoger la m√©trica correcta ya que para datasets desbalanceados la m√©trica de accuracy suele presentar buenos valores pero en realidad las predicciones no son buenas y es por la forma en c√≥mo se calcula esta m√©trica que puede llevar a interpretaciones erroneas en cambio el f1-score es la ideal para este tipo de casos ya que maneja mejor este tipo de problemas.\n",
    "    \n",
    "Saludos!\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
